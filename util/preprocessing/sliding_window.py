from torchvision.datasets.video_utils import VideoClips
import torchvision, cv2, torch
import numpy as np

"""
The script applies the sliding window method for a given video. However, each sample 
that is generated by the sliding window is divided into subclips due to memory constraints.
All subclips for a sample are located in a single directory
"""

def rotate_image(image, angle):
    image_center = tuple(np.array(image.shape[1::-1]) / 2)
    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)
    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)
    return result

def main(path, label):
    T = 300
    no_subsets = 2

    videoclips = VideoClips([path], clip_length_in_frames=int(T/no_subsets), frames_between_clips=1)
    
    rotation = 0
    for i in range(len(videoclips)):
        clip,_,_, _ = videoclips.get_clip(i)

        clip = clip.numpy()
        
        if i % no_subsets == 0:
            # New sample, create new preprocess values
            rnd = np.random.uniform(-1,1)
            rotation = 45 * rnd
            # Create save directory
            pass

        # Preprocess
        for f in range(len(clip)):
            img = clip[f]
            clip[f] = rotate_image(img, rotation)
        
        
        # Save
        clip = torch.tensor(clip)
        torchvision.io.write_video("clip0.mp4", clip, 30)

        exit()


    # exit()
    # torchvision.io.write_video("clip0.mp4", clip, 30)
    # print(clip.shape)
    # clip,_,_, _ = videoclips.get_clip(1)
    # torchvision.io.write_video("clip1.mp4", clip, 30)
    # print(clip.shape)


if __name__ == "__main__":
    main("../datasets/weightlifting/sliding_window/full_videos/backsquat.mp4", "backsquat")